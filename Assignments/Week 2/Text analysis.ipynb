{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting number of paragraphs\n",
    "A reoccuring pattern after each paragraph is a full stop punctuation mark **'.'** followed by two break lines **'\\n\\n'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Types of data science questions\\n\\nIn this lesson, we’re going to be a little more conceptual and look at some of the types of analyses data scientists\\nemploy to answer questions in data science', 'The main divisions of data science questions\\nThere are, broadly speaking, six categories in which data analyses fall. In the approximate order of difficulty, they\\nare:\\n\\n1. Descriptive\\n2. Exploratory\\n3. Inferential\\n4. Predictive\\n5. Causal\\n6. Mechanistic\\n\\nLet’s explore the goals of each of these types and look at some examples of each analysis!\\n\\n1. Descriptive analysis\\n\\nThe goal of descriptive analysis is to describe or summarize a set of data. Whenever you get a new dataset to\\nexamine, this is usually the first kind of analysis you will perform. Descriptive analysis will generate simple\\nsummaries about the samples and their measurements. You may be familiar with common descriptive statistics:\\nmeasures of central tendency (eg: mean, median, mode) or measures of variability (eg: range, standard\\ndeviations or variance)', 'This type of analysis is aimed at summarizing your sample – not for generalizing the results of the analysis to a\\nlarger population or trying to make conclusions. Description of data is separated from making interpretations;\\ngeneralizations and interpretations require additional statistical steps', 'Some examples of purely descriptive analysis can be seen in censuses. Here, the government collects a series\\nof measurements on all of the country’s citizens, which can then be summarized. Here, you are being shown the\\nage distribution in the US, stratified by sex. The goal of this is just to describe the distribution. There is no\\ninferences about what this means or predictions on how the data might trend in the future. It is just to show you a\\nsummary of the data collected', '2. Exploratory analysis\\n\\nThe goal of exploratory analysis is to examine or explore the data and find relationships that weren’t previously\\nknown. Exploratory analyses explore how different measures might be related to each other but do not confirm\\nthat relationship as causitive. \\n\\nYou’ve probably heard the phrase “Correlation does not imply causation” and\\nexploratory analyses lie at the root of this saying. Just because you observe a relationship between two variables\\nduring exploratory analysis, it does not mean that one necessarily causes the other.\\nBecause of this, exploratory analyses, while useful for discovering new connections, should not be the final say in\\nanswering a question! It can allow you to formulate hypotheses and drive the design of future studies and data\\ncollection, but exploratory analysis alone should never be used as the final say on why or how data might be\\nrelated to each other', 'Going back to the census example from above, rather than just summarizing the data points within a single\\nvariable, we can look at how two or more variables might be related to each other. In the plot below, we can see\\nthe percent of the workforce that is made up of women in various sectors and how that has changed between\\n2000 and 2016. Exploring this data, we can see quite a few relationships. Looking just at the top row of the data,\\nwe can see that women make up a vast majority of nurses and that it has slightly decreased in 16 years. While\\nthese are interesting relationships to note, the causes of these relationships is not apparent from this analysis. All\\nexploratory analysis can tell us is that a relationship exists, not the cause', '3. Inferential analysis\\n\\nThe goal of inferential analyses is to use a relatively small sample of data to infer or say something about\\nthe population at large. Inferential analysis is commonly the goal of statistical modelling, where you have a small\\namount of information to extrapolate and generalize that information to a larger group', 'Inferential analysis typically involves using the data you have to estimate that value in the population and then\\ngive a measure of your uncertainty about your estimate. Since you are moving from a small amount of data and\\ntrying to generalize to a larger population, your ability to accurately infer information about the larger population\\ndepends heavily on your sampling scheme - if the data you collect is not from a representative sample of the\\npopulation, the generalizations you infer won’t be accurate for the population', 'Unlike in our previous examples, we shouldn’t be using census data in inferential analysis - a census already\\ncollects information on (functionally) the entire population, there is nobody left to infer to; and inferring data from\\nthe US census to another country would not be a good idea because the US isn’t necessarily representative of\\nanother country that we are trying to infer knowledge about. Instead, a better example of inferential analysis is a\\nstudy in which a subset of the US population was assayed for their life expectancy given the level of air pollution\\nthey experienced. This study uses the data they collected from a sample of the US population to infer how air\\npollution might be impacting life expectancy in the entire US', '4. Predictive analysis\\n\\nThe goal of predictive analysis is to use current data to make predictions about future data. Essentially, you\\nare using current and historical data to find patterns and predict the likelihood of future outcomes', 'Like in inferential analysis, your accuracy in predictions is dependent on measuring the right variables. If you\\naren’t measuring the right variables to predict an outcome, your predictions aren’t going to be accurate.\\nAdditionally, there are many ways to build up prediction models with some being better or worse for specific\\ncases, but in general, having more data and a simple model generally performs well at predicting future\\noutcomes', 'All this being said, much like in exploratory analysis, just because one variable may predict another, it does not\\nmean that one causes the other; you are just capitalizing on this observed relationship to predict the second\\nvariable', 'A common saying is that prediction is hard, especially about the future. There aren’t easy ways to gauge how\\nwell you are going to predict an event until that event has come to pass; so evaluating different approaches or\\nmodels is a challenge', 'We spend a lot of time trying to predict things - the upcoming weather, the outcomes of sports events, and in the\\nexample we’ll explore here, the outcomes of elections. We’ve previously mentioned Nate Silver\\nof FiveThirtyEight, where they try and predict the outcomes of U.S. elections (and sports matches, too!). Using\\nhistorical polling data and trends and current polling, FiveThirtyEight builds models to predict the outcomes in the\\nnext US Presidential vote - and has been fairly accurate at doing so! FiveThirtyEight’s models accurately\\npredicted the 2008 and 2012 elections and was widely considered an outlier in the 2016 US elections, as it was\\none of the few models to suggest Donald Trump at having a chance of winning', '5. Causal analysis\\n\\nThe caveat to a lot of the analyses we’ve looked at so far is that we can only see correlations and can’t get at the\\ncause of the relationships we observe. Causal analysis fills that gap; the goal of causal analysis is to see what\\nhappens to one variable when we manipulate another variable - looking at the cause and effect of\\na relationship', 'Generally, causal analyses are fairly complicated to do with observed data alone; there will always be questions\\nas to whether it is correlation driving your conclusions or that the assumptions underlying your analysis are valid.\\nMore often, causal analyses are applied to the results of randomized studies that were designed to identify\\ncausation. Causal analysis is often considered the gold standard in data analysis, and is seen frequently in\\nscientific studies where scientists are trying to identify the cause of a phenomenon, but often getting appropriate\\ndata for doing a causal analysis is a challenge', 'One thing to note about causal analysis is that the data is usually analysed in aggregate and observed\\nrelationships are usually average effects; so, while on average giving a certain population a drug may alleviate\\nthe symptoms of a disease, this causal relationship may not hold true for every single affected individual.\\nAs we’ve said, many scientific studies allow for causal analyses. Randomized control trials for drugs are a prime\\nexample of this. For example, one randomized control trial examined the effects of a new drug on treating infants\\nwith spinal muscular atrophy. Comparing a sample of infants receiving the drug versus a sample receiving a\\nmock control, they measure various clinical outcomes in the babies and look at how the drug affects the\\noutcomes', '6. Mechanistic analysis\\n\\nMechanistic analyses are not nearly as commonly used as the previous analyses - the goal of mechanistic\\nanalysis is to understand the exact changes in variables that lead to exact changes in other variables. These\\nanalyses are exceedingly hard to use to infer much, except in simple situations or in those that are nicely\\nmodeled by deterministic equations. Given this description, it might be clear to see how mechanistic analyses are\\nmost commonly applied to physical or engineering sciences; biological sciences, for example, are far too noisy of\\ndata sets to use mechanistic analysis. Often, when these analyses are applied, the only noise in the data is\\nmeasurement error, which can be accounted for', 'You can generally find examples of mechanistic analysis in material science experiments. Here, we have a study\\non biocomposites (essentially, making biodegradable plastics) that was examining how biocarbon particle size,\\nfunctional polymer type and concentration affected mechanical properties of the resulting “plastic.” They are able\\nto do mechanistic analyses through a careful balance of controlling and manipulating variables with very accurate\\nmeasures of both those variables and the desired outcome', 'Summary\\n\\nIn this lesson we’ve covered the various types of data analysis, their goals, and looked at a few examples of each\\nto demonstrate what each analysis is capable of (and importantly, what it is not).']\n"
     ]
    }
   ],
   "source": [
    "with open ('Data_science_questions.txt', encoding='utf-8') as f:\n",
    "    contents = f.read().split('.\\n\\n')\n",
    "    print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(contents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text file has approximaely 20 paragraphs, next we will build a function that will count the number of times a word appears in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "descriptive appears 5 times.\n",
      "exploratory appears 12 times.\n",
      "inferential appears 18 times.\n",
      "predictive appears 20 times.\n",
      "causal appears 30 times.\n",
      "mechanistic appears 35 times.\n"
     ]
    }
   ],
   "source": [
    "word_list = []\n",
    "def word_count(word):\n",
    "    \"\"\"\"Count the number of times a word appears in a text file\"\"\"\"\n",
    "    with open ('Data_science_questions.txt', encoding='utf-8') as f:\n",
    "        contents = f.read().upper().split(' ')\n",
    "        for x in contents:\n",
    "            if word.upper() == x:\n",
    "                word_list.append(x)\n",
    "        print(word + ' appears ' + str(len(word_list)) + ' times.')\n",
    "\n",
    "keywords = ['descriptive', 'exploratory', 'inferential', 'predictive', 'causal', 'mechanistic']\n",
    "\n",
    "for keyword in keywords:\n",
    "    word_count(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
